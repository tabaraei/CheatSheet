{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yN5JFHgzIR1f",
        "C0mEiY7CDlRN",
        "rBW2rZ-IDptN",
        "ezEdov5UDw4b",
        "FxIXWvCkGKG0",
        "UdWq-qsQYz_i",
        "eAlT9J-Q76HR"
      ],
      "authorship_tag": "ABX9TyPxuZSgvSmuZc+n0N39xIId",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tabaraei/CheatSheet/blob/master/notebooks/PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting Started"
      ],
      "metadata": {
        "id": "yN5JFHgzIR1f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZNNCi9b-W-w",
        "outputId": "b0eb311d-2b72-41d7-ace7-30579b1302a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Check if GPU is available\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1])\n",
        "print(x.device)\n",
        "x = x.to('cuda')\n",
        "print(x.device)\n",
        "y = torch.tensor([1], device='cuda')\n",
        "print(y.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UJTqnBJXovY",
        "outputId": "014d19c2-2446-45a9-dfc8-af3598a06952"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "cuda:0\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Tensors"
      ],
      "metadata": {
        "id": "C0mEiY7CDlRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([1,2,3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPDAP-jdG3xH",
        "outputId": "22bb77e5-dfc1-43fc-cf58-d8cfb97ab601"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros(2,3, dtype=torch.int32), \\\n",
        "torch.ones(2), \\\n",
        "torch.empty(2), \\\n",
        "torch.rand(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyZWFB_A-wVk",
        "outputId": "807db47c-59e2-48a5-f5c5-acb5198d809e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0, 0, 0],\n",
              "         [0, 0, 0]], dtype=torch.int32),\n",
              " tensor([1., 1.]),\n",
              " tensor([-5.8644e-16,  3.0801e-41]),\n",
              " tensor([0.4345, 0.0029]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array = np.array([1,2,3])\n",
        "torch.from_numpy(array), \\\n",
        "torch.tensor(array), \\\n",
        "torch.tensor(array).numpy()\n",
        "# Careful that modifying numpy array will affect tensor and vice versa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR6ryJx9-yNU",
        "outputId": "115fab2a-2431-45c1-a506-c0fe40ff7042"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3]), tensor([1, 2, 3]), array([1, 2, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mathematical Operations with Tensors"
      ],
      "metadata": {
        "id": "rBW2rZ-IDptN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.ones(3)\n",
        "t2 = torch.tensor([1,2.,3]) # dtype of all values will be the same\n",
        "t2, t2.shape, t2.dtype, t2.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWoNms4HCel6",
        "outputId": "d8e5dd69-7de5-42d6-c8af-ad7d4cba84b3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3.]), torch.Size([3]), torch.float32, torch.Size([3]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: every function with underscore inplaces value\n",
        "# main operations are: add, sub, mul, div\n",
        "t1 + t2, torch.add(t1, t2), t2.add_(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viESPXrMCw5G",
        "outputId": "5e1852d3-aafc-4f3c-ad70-9447b86c5692"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([2., 3., 4.]), tensor([2., 3., 4.]), tensor([2., 3., 4.]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Slicing within Tensors"
      ],
      "metadata": {
        "id": "ezEdov5UDw4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.rand(3,4)\n",
        "t1, t1[:,1], t1[1:3, 1:4], t1[0, 0].item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6Tdx5PBDFOg",
        "outputId": "41898d83-fe90-4043-ba3f-9b276d936151"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.1438, 0.8735, 0.5152, 0.1795],\n",
              "         [0.1737, 0.5774, 0.7629, 0.5976],\n",
              "         [0.1775, 0.8521, 0.2266, 0.9676]]),\n",
              " tensor([0.8735, 0.5774, 0.8521]),\n",
              " tensor([[0.5774, 0.7629, 0.5976],\n",
              "         [0.8521, 0.2266, 0.9676]]),\n",
              " 0.1438007950782776)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reshaping Tensors"
      ],
      "metadata": {
        "id": "FxIXWvCkGKG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.rand(16)\n",
        "t1.view(-1, 8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo9_U0lnGNgc",
        "outputId": "a4eb8482-fcce-4531-d30b-59b64d498b42"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6165, 0.9824, 0.1246, 0.0717, 0.3715, 0.5199, 0.0811, 0.6979],\n",
              "        [0.1035, 0.7064, 0.5744, 0.6174, 0.5151, 0.5576, 0.4827, 0.7918]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.device(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4mktJzXI1KF",
        "outputId": "ce70a2a0-a585-44fe-eaa0-b1467ce3b303"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjZGFNHgJR7J",
        "outputId": "f2e8df89-edbd-4a64-b7d7-8193f5fbd4a7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradients"
      ],
      "metadata": {
        "id": "UdWq-qsQYz_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# forward pass\n",
        "y_hat = w*x\n",
        "loss = (y_hat - y)**2\n",
        "print(loss)\n",
        "\n",
        "# backward pass\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "\n",
        "# x.requires_grad_(False)\n",
        "# use x.grad.zero_() at the end of loops!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3loxuxVY2Wg",
        "outputId": "20010e08-7139-4059-975a-740530844c1c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Regression"
      ],
      "metadata": {
        "id": "eAlT9J-Q76HR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model selection and params\n",
        "# loss function and optimizer\n",
        "# Training loop:\n",
        "# - forward pass\n",
        "# - backward pass\n",
        "# - update weights"
      ],
      "metadata": {
        "id": "wxpI-l6X7cQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simplest Solution Without Using AutoGrad\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([1,2,3,4], dtype=np.float32)\n",
        "Y = np.array([2,4,6,8], dtype=np.float32)\n",
        "W = 0.0\n",
        "\n",
        "# model prediction: f = x * w\n",
        "def forward(x):\n",
        "  return W * x\n",
        "\n",
        "# loss: MSE = 1/N (wx - y)^2\n",
        "def loss(y, y_pred):\n",
        "  return ((y - y_pred)**2).mean()\n",
        "\n",
        "# gradient: grad = 1/N 2x (wx - y)\n",
        "def gradient(x, y, y_pred):\n",
        "  return np.dot(2*x, y_pred-y).mean()\n",
        "\n",
        "print(f'prediction before training: {forward(5)}')\n",
        "\n",
        "# training\n",
        "learning_rate = 0.01\n",
        "n_iters = 20\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  y_pred = forward(X)\n",
        "  err = loss(Y, y_pred)\n",
        "  dw = gradient(X, Y, y_pred)\n",
        "  W -= learning_rate*dw\n",
        "\n",
        "  if epoch % 2 == 0:\n",
        "    print(f'epoch {epoch+1}: , w = {W}, loss = {err}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwBEDvX38BfS",
        "outputId": "edadb257-611a-42d1-abe3-1c312ac74628"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction before training: 0.0\n",
            "epoch 1: , w = 1.2, loss = 30.0\n",
            "epoch 3: , w = 1.871999988555908, loss = 0.7680001854896545\n",
            "epoch 5: , w = 1.9795200133323667, loss = 0.019660834223031998\n",
            "epoch 7: , w = 1.9967231869697568, loss = 0.0005033080233260989\n",
            "epoch 9: , w = 1.999475698471069, loss = 1.2884394891443662e-05\n",
            "epoch 11: , w = 1.9999160599708554, loss = 3.297340072094812e-07\n",
            "epoch 13: , w = 1.9999865984916685, loss = 8.487816671731707e-09\n",
            "epoch 15: , w = 1.9999978351593015, loss = 2.1679014139408537e-10\n",
            "epoch 17: , w = 1.9999996304512022, loss = 5.076827847005916e-12\n",
            "epoch 19: , w = 1.9999999165534972, loss = 1.3145040611561853e-13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Backward AutoGrad\n",
        "\n",
        "import torch\n",
        "\n",
        "X = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
        "Y = torch.tensor([2,4,6,8], dtype=torch.float32)\n",
        "W = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# model prediction: f = x * w\n",
        "def forward(x):\n",
        "  return W * x\n",
        "\n",
        "# loss: MSE = 1/N (wx - y)^2\n",
        "def loss(y, y_pred):\n",
        "  return ((y - y_pred)**2).mean()\n",
        "\n",
        "print(f'prediction before training: {forward(5)}')\n",
        "\n",
        "# training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  y_pred = forward(X)\n",
        "  err = loss(Y, y_pred)\n",
        "  err.backward()\n",
        "  with torch.no_grad():\n",
        "    W -= learning_rate*W.grad\n",
        "\n",
        "  W.grad.zero_()\n",
        "  if epoch % 10 == 0:\n",
        "    print(f'epoch {epoch+1}: , w = {W}, loss = {err}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCLWwaKHIeuz",
        "outputId": "cab10f17-473a-439e-b704-067aaf0ed520"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction before training: 0.0\n",
            "epoch 1: , w = 0.29999998211860657, loss = 30.0\n",
            "epoch 11: , w = 1.6653136014938354, loss = 1.1627856492996216\n",
            "epoch 21: , w = 1.934108853340149, loss = 0.0450688973069191\n",
            "epoch 31: , w = 1.987027645111084, loss = 0.0017468547448515892\n",
            "epoch 41: , w = 1.9974461793899536, loss = 6.770494655938819e-05\n",
            "epoch 51: , w = 1.9994971752166748, loss = 2.6243997126584873e-06\n",
            "epoch 61: , w = 1.9999010562896729, loss = 1.0175587306093803e-07\n",
            "epoch 71: , w = 1.9999804496765137, loss = 3.9741685498029256e-09\n",
            "epoch 81: , w = 1.999996304512024, loss = 1.4670220593870908e-10\n",
            "epoch 91: , w = 1.9999992847442627, loss = 5.076827847005916e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# With Predefined Optimizer and Loss Funcionts\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
        "Y = torch.tensor([2,4,6,8], dtype=torch.float32)\n",
        "W = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# model prediction: f = x * w\n",
        "def forward(x):\n",
        "  return W * x\n",
        "\n",
        "# loss: MSE = 1/N (wx - y)^2\n",
        "loss = nn.MSELoss()\n",
        "\n",
        "print(f'prediction before training: {forward(5)}')\n",
        "\n",
        "# training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "optimizer = torch.optim.SGD([W], lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  y_pred = forward(X)\n",
        "  err = loss(Y, y_pred)\n",
        "  err.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(f'epoch {epoch+1}: , w = {W}, loss = {err}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-Vz1u-8QDNg",
        "outputId": "eaa19577-c333-4c90-d4be-90064e3cc0a6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction before training: 0.0\n",
            "epoch 1: , w = 0.29999998211860657, loss = 30.0\n",
            "epoch 11: , w = 1.6653136014938354, loss = 1.1627856492996216\n",
            "epoch 21: , w = 1.934108853340149, loss = 0.0450688973069191\n",
            "epoch 31: , w = 1.987027645111084, loss = 0.0017468547448515892\n",
            "epoch 41: , w = 1.9974461793899536, loss = 6.770494655938819e-05\n",
            "epoch 51: , w = 1.9994971752166748, loss = 2.6243997126584873e-06\n",
            "epoch 61: , w = 1.9999010562896729, loss = 1.0175587306093803e-07\n",
            "epoch 71: , w = 1.9999804496765137, loss = 3.9741685498029256e-09\n",
            "epoch 81: , w = 1.999996304512024, loss = 1.4670220593870908e-10\n",
            "epoch 91: , w = 1.9999992847442627, loss = 5.076827847005916e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# With Predefined Models, or Class Models\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([[1],[2],[3],[4]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2],[4],[6],[8]], dtype=torch.float32)\n",
        "X_test = torch.tensor([5], dtype=torch.float32)\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "# # We could use a model class\n",
        "# class LinearRegression(nn.Module):\n",
        "#   def __init__(self, input_dim, output_dim):\n",
        "#     super(LinearRegression, self).__init__()\n",
        "#     # define layers\n",
        "#     self.lin= nn.Linear(input_dim, output_dim)\n",
        "#   def forward(self, x):\n",
        "#     return self.lin(x)\n",
        "# model = LinearRegression(n_features, n_features)\n",
        "\n",
        "# or use defined models\n",
        "model = nn.Linear(in_features=n_features, out_features=n_features)\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "learning_rate = 0.01\n",
        "n_iters = 2800\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "print(f'prediction before training: {model(X_test).item()}')\n",
        "for epoch in range(n_iters):\n",
        "  y_pred = model(X)\n",
        "  err = loss(Y, y_pred)\n",
        "  err.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch % (n_iters/10) == 0:\n",
        "    [w, b] = model.parameters()\n",
        "    print(f'epoch {epoch+1}: w = {w[0,0].item():.3f}, b = {b[0].item():.3f}, loss = {err:.3f}, pred = {model(X_test).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDztJ7Omj51S",
        "outputId": "1b0a2f0a-c476-42bb-a067-dc91b5f4c5f7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction before training: -2.3496627807617188\n",
            "epoch 1: w = -0.302, b = 1.036, loss = 41.454, pred = -0.475\n",
            "epoch 281: w = 1.760, b = 0.704, loss = 0.083, pred = 9.507\n",
            "epoch 561: w = 1.897, b = 0.304, loss = 0.016, pred = 9.787\n",
            "epoch 841: w = 1.955, b = 0.131, loss = 0.003, pred = 9.908\n",
            "epoch 1121: w = 1.981, b = 0.057, loss = 0.001, pred = 9.960\n",
            "epoch 1401: w = 1.992, b = 0.025, loss = 0.000, pred = 9.983\n",
            "epoch 1681: w = 1.996, b = 0.011, loss = 0.000, pred = 9.993\n",
            "epoch 1961: w = 1.998, b = 0.005, loss = 0.000, pred = 9.997\n",
            "epoch 2241: w = 1.999, b = 0.002, loss = 0.000, pred = 9.999\n",
            "epoch 2521: w = 2.000, b = 0.001, loss = 0.000, pred = 9.999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All in One\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Prepare Data\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32)).view(y_numpy.shape[0], 1)\n",
        "X_test = torch.tensor([5], dtype=torch.float32)\n",
        "n_samples, n_features = X.shape\n",
        "print(f'Features shape: {list(X.shape)}, Classes shape: {list(y.shape)}')\n",
        "\n",
        "# Model and Optimizer Selection\n",
        "model = nn.Linear(in_features=n_features, out_features=n_features)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.5)\n",
        "loss = nn.MSELoss()\n",
        "learning_rate = 0.01\n",
        "n_iters = 300\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(n_iters):\n",
        "  y_pred = model(X)\n",
        "  err = loss(y_pred, y)\n",
        "  err.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch % (n_iters/10) == 0:\n",
        "    [w, b] = model.parameters()\n",
        "    print(f'epoch {epoch+1}: w = {w[0,0].item():.3f}, b = {b[0].item():.3f}, loss = {err:.3f}, pred = {model(X_test).item():.3f}')\n",
        "\n",
        "# Plot\n",
        "predicted = model(X).detach().numpy()\n",
        "_ = plt.plot(X_numpy, y_numpy, 'co')\n",
        "_ = plt.plot(X_numpy, predicted, 'k')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "JwAvMW21wc-X",
        "outputId": "c402e855-ba43-42aa-8be0-f70646f6f5c3"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: [100, 1], Classes shape: [100, 1]\n",
            "epoch 1: w = 1.550, b = -0.548, loss = 5726.705, pred = 7.202\n",
            "epoch 31: w = 51.980, b = 4.871, loss = 1112.806, pred = 264.770\n",
            "epoch 61: w = 71.141, b = 5.086, loss = 440.355, pred = 360.791\n",
            "epoch 91: w = 78.247, b = 4.641, loss = 347.702, pred = 395.876\n",
            "epoch 121: w = 80.896, b = 4.329, loss = 334.711, pred = 408.810\n",
            "epoch 151: w = 81.888, b = 4.173, loss = 332.873, pred = 413.611\n",
            "epoch 181: w = 82.260, b = 4.103, loss = 332.611, pred = 415.402\n",
            "epoch 211: w = 82.400, b = 4.074, loss = 332.574, pred = 416.073\n",
            "epoch 241: w = 82.453, b = 4.062, loss = 332.568, pred = 416.325\n",
            "epoch 271: w = 82.472, b = 4.057, loss = 332.568, pred = 416.419\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "FOWRFqEL727z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Load and Split the Data\n",
        "dataset = datasets.load_breast_cancer()\n",
        "X, y = dataset.data, dataset.target\n",
        "X_train, X_test, y_train, y_test = \\\n",
        "  train_test_split(X, y, train_size=0.8, random_state=1)\n",
        "n_features = X.shape[1]\n",
        "\n",
        "# Preprocess the Data\n",
        "scalar = StandardScaler()\n",
        "X_train = scalar.fit_transform(X_train)\n",
        "X_test = scalar.fit_transform(X_test)\n",
        "\n",
        "# Prepare the \n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32)).view(y_train.shape[0], 1)\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32)).view(y_test.shape[0], 1)\n",
        "\n",
        "# Model Selection\n",
        "\n",
        "# Loss and Optimizer\n",
        "\n",
        "# Training Loop"
      ],
      "metadata": {
        "id": "q7LHtNpm76rc"
      },
      "execution_count": 113,
      "outputs": []
    }
  ]
}